{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Few More Handy Pandas Ditties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Python 2 & 3 Compatibility\n",
    "from __future__ import print_function, division\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Read in some Weather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read it in, set the Date/Time as the index (we're going to build a time series!)\n",
    "weather = pd.read_csv('data/weather.csv', index_col='Date/Time')\n",
    "# Take a look\n",
    "weather['Temp (C)'].plot(figsize=(15, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Examine the columns\n",
    "weather.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Examine some of the values\n",
    "weather.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying Functions Across `Series` or `Dataframe`\n",
    "Often times we'll want to update a series or Dataframe by applying functions to all of the values in a column or columns.  There are 3 main functions for doing this: `map()`, `apply()`, and `applymap()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`map()`**  \n",
    "Run a function on every element in a **`Series`**.  For instance, let's try converting temperature to Fahrenheit and adding that column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Function that converts Celsius to Fahrenheit\n",
    "def celsius_to_fahrenheit(temp):\n",
    "    return (9.0*temp/5.0) + 32\n",
    "\n",
    "# Use it to make the conversion and add a new column for it\n",
    "weather['Temp (F)'] = weather['Temp (C)'].map(celsius_to_fahrenheit)\n",
    "weather.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Lambda Functions\n",
    "Often we won't want to explicitly write out the function definition for something like this because we'll just use it once and never again.  This is where \"throwaway\" or \"temp\" functions come in with the `lambda` operator.  Here's how you would do the same task with a `lambda`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weather['Temp (F)'] = weather['Temp (C)'].map(lambda x: 9.0*x/5.0 + 32)\n",
    "weather.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`apply()`**  \n",
    "This is for functions that operate on entire arrays (`Series`) within a `Dataframe`.  Examples would include your usual aggregation functions like `sum()`, `mean()`, etc.  Here for example is how we might use it to find the range for each numeric column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weather.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Select only temperature columns and find their range\n",
    "weather_temps = weather[['Temp (C)', 'Temp (F)']]\n",
    "weather_temps.apply(lambda x: x.max() - x.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`applymap`**  \n",
    "This does element-wise operations on everything in a **`Dataframe`**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Function to format numerics\n",
    "format = lambda x: '%.2f' % x\n",
    "weather_temps.applymap(format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### String Operators\n",
    "`map`, `apply`, and `applymap` are general and allow you to write just about any function to apply to elements in dataframes.  However, `pandas` has a bunch of its own built-in functions for these things, especially when working with strings.\n",
    "\n",
    "The `Weather` column is our only string here, so let's use it to look at some string operators.  First let's check out the unique values in there:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weather.Weather.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`replace()`**  \n",
    "Just to demonstrate, let's replace all of the occurrences of \"Fog\" with \" Fog\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spacey_fog = weather.Weather.str.replace('^Fog', ' Fog')\n",
    "spacey_fog.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`strip()`**  \n",
    "Now let's undo our work with `strip()` to remove leading/trailing whitespace:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spacey_fog.str.strip().unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`contains()`**  \n",
    "Let's use this method to check if the Weather contains \"Snow\" and if it does store that is `is_snowing`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "is_snowing = weather.Weather.str.contains('Snow')\n",
    "weather[is_snowing]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Series  \n",
    "As you're probably well aware by now, `pandas` can be indexed by datetimes without batting an eye.  Effectively, this means it handles **Time Series Data** out of the box!\n",
    "\n",
    "Here are a few nice methods for working with time series, we'll expand on these when we discuss time series explicitly later in the course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`date_range()`**  \n",
    "Creates a `DateTimeIndex` which can index a time series.  This is especially useful if you don't already have one or want to make changes to one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Example date range with frequency specifier every 3 days, starting january 1st, for 6 cycles\n",
    "dates = pd.date_range('20130101', periods=6, freq='3D')\n",
    "dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a random dataframe with it\n",
    "df = pd.DataFrame(np.random.randn(6,4), index=dates, columns=list('ABCD'))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`resample()`**  \n",
    "Every datetime index has an inherent frequency.  For instance, in the example above the frequency was every 3 days.  The `resample()` method is so valuable in that it allows us to either **upsample** or **downsample** to change the frequency of the observations.  Upsampling involved getting more frequent observations--obviously this is limited by the total number that you have--but you can also potentially **interpolate** values for these new observations and `pandas` has methods for doing this.  In downsampling, you're simple reducing the observations down to the appropriate frequency.\n",
    "\n",
    "Let's use resampling along with our `is_snowing` variable to determine the snowiest **month** (as opposed to the current data by day)!  When downsampling like this, you can specify parameters as to how to aggregate the observations being dropped.  Here we'll use the **mean**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# What's happening here?\n",
    "is_snowing.astype(float).resample('M', how=np.mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joining Related Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`merge()`**  \n",
    "What if now we wanted to join together our `is_snowing` with the columns from `weather` so they're all alligned in the same Dataframe.  This is literally called a **join** in classical SQL (database query language) terms, and `pandas` has a few ways to accomplish it.  `merge` is the best, so let's start there:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# What's happening?\n",
    "weather_snowing = weather.merge(pd.DataFrame(is_snowing), left_index=True, right_index=True)\n",
    "weather_snowing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`join()`**  \n",
    "This is slightly different than `merge`, we prefer `merge`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "weather.join(is_snowing, how=\"inner\", rsuffix='2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`concat()`**  \n",
    "This concatenates 2 dataframes vertically, aka adds a bunch of rows to a bunch of other rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weather_concat = pd.concat([weather.iloc[0:100,], weather.iloc[200:300,]])\n",
    "weather_concat.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`append()`**  \n",
    "Add a single row to a DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weather_append = weather_concat.append(weather.iloc[305,])\n",
    "weather_append.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarizing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`corr()`**  \n",
    "This function is really useful as it calculates pairwise **correlations** between all of the variables in your data table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weather.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`cov()`**  \n",
    "Similarly, here is **covariance**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weather.cov()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical Variables\n",
    "`pandas` let's you work with categorical variables.  These are variables that can take only a certain set of values (\"R\", \"PG-13\", \"PG\", \"G\").  We'll see this a lot later on, for now just an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weather['Weather Cat'] = weather.Weather.astype('category')\n",
    "weather.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Misc\n",
    "\n",
    "**`shift()`**  \n",
    "Shift a column forward a backward some number of rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weather['Forward'] = weather['Temp (F)'].shift(periods=2)\n",
    "weather['Backward'] = weather['Temp (F)'].shift(periods=-1)\n",
    "weather"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`diff()`**  \n",
    "Calculate the diff between rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weather['Temp Diff'] = weather['Temp (F)'].diff()\n",
    "weather"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
