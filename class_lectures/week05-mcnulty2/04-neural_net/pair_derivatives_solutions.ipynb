{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions ###\n",
    "\n",
    "1. What is the derivative of $x^{2}$?\n",
    "\n",
    "2. What is the derivative of log(x)?\n",
    "\n",
    "3. What is the derivative of $e^{x}$?\n",
    "\n",
    "4. z = f(y) & y = g(x) what is $\\frac{dz}{dx}$?\n",
    "\n",
    "5. How would you numerically evaluate a gradient? What does the python code look like?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Derivatives (1-3) ###\n",
    "Here's an online calculator: https://www.symbolab.com/solver/derivative-calculator/\n",
    "\n",
    "\n",
    "(1) Derivative of $x^2$ = $2x$ (by applying the power rule: $\\frac{d}{dx}\\left(x^a\\right)=a\\cdot x^{a-1}$)\n",
    "\n",
    "\n",
    "(2) Derivative of $log(x)$ = $1/x$ (this is a common derivative: $\\frac{d}{dx}\\left(\\ln \\left(x\\right)\\right)=\\frac{1}{x}$)\n",
    "\n",
    "\n",
    "(3) Derivative of $e^x$ = $e^x$ (this is a common derivative: $\\frac{d}{dx}\\left(e^x\\right)=e^x$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Chain Rule (4) ###\n",
    "\n",
    "z = f(g(x))\n",
    "\n",
    "u = g(x)\n",
    "\n",
    "Format 1: dz/dx = dz/du * du/dx\n",
    "\n",
    "Format 2: dz/dx = f'(g(x)) * g'(x)\n",
    "\n",
    "[5 minute Khan Academy video on the chain rule](https://www.khanacademy.org/math/ap-calculus-ab/ab-derivative-rules/ab-chain-rule/v/chain-rule-introduction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerically evaluate a gradient (5) ###\n",
    "\n",
    "The gradient is the direction of the steepest climb up a hill.\n",
    "\n",
    "The gradient function returns a vector, with each component being a partial derivative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Two dimensional case ####\n",
    "\n",
    "Let's say we have a function:\n",
    "\n",
    "$f(x,y) = x^2 + sin(y)$\n",
    "\n",
    "Here's a visual of the function:\n",
    "<https://academo.org/demos/3d-surface-plotter/?expression=x%5E2%2Bsin(y)&xRange=-50%2C+50&yRange=-50%2C+50&resolution=25>\n",
    "\n",
    "The gradient of the function at a particular point should return a vector. That vector tells us the direction of the steepest climb from that point.\n",
    "\n",
    "Each value in the vector is the partial derivative with respect to a particular axis. So:\n",
    "\n",
    "$\\nabla f(x,y) = [\\frac{df(x,y)}{dx},\\frac{df(x,y)}{dy}$]\n",
    "\n",
    "Here's a reminder of the equation for a derivative:\n",
    "\n",
    "$f'(a) = \\lim_{h \\to 0}\\frac{f(a+h)-f(a)}{h}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[40.00000330961484, 1.0000007932831068]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import to use sin function\n",
    "import math\n",
    "\n",
    "# define a small amount of change\n",
    "h = 1e-8\n",
    "\n",
    "# define a function\n",
    "def func(x,y):\n",
    "    return x**2 + math.sin(y)\n",
    "\n",
    "# to find the gradient, find the partial derivative in each direction\n",
    "def gradient(func,x,y):\n",
    "    partial_x = (func(x+h,y)-func(x,y))/h\n",
    "    partial_y = (func(x,y+h)-func(x,y))/h\n",
    "    return [partial_x, partial_y]\n",
    "\n",
    "# run the gradient function at a point (x=20, y=0)\n",
    "gradient(func,20,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### General case ####\n",
    "\n",
    "In the general case below, this will take any number of dimensions.\n",
    "\n",
    "Also, I am using a different derivative equation. The derivative we were using before is one-sided:\n",
    "\n",
    "$f'(a) = \\lim_{h \\to 0}\\frac{f(a+h)-f(a)}{h}$\n",
    "\n",
    "Here's a two-sided derivative equation that centers around the point (vs the one above that is off center):\n",
    "\n",
    "$f'(a) = \\lim_{h \\to 0}\\frac{f(a+h)-f(a-h)}{2h}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = [20, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func(*t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[40.00000330961484, 1.0000007932831068]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h = 1e-8\n",
    "\n",
    "def gradient_general(func,*args):\n",
    "    partials = []\n",
    "    for i, dim in enumerate(args):\n",
    "        point_plus_h = list(args)\n",
    "        point_plus_h[i] += h\n",
    "        point_minus_h = list(args)\n",
    "        point_minus_h[i] -= h\n",
    "        partial = (func(*point_plus_h) - func(*point_minus_h))/(2*h)\n",
    "        partials.append(partial)\n",
    "    return partials\n",
    "\n",
    "gradient_general(func,20,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load in data\n",
    "iris = load_iris()\n",
    "X = np.hstack([np.ones((100, 1)), iris.data[0:100]])\n",
    "y = iris.target[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Starting weights\n",
    "w = np.random.randn(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x, w):\n",
    "    return (1)/(1 + np.exp(-np.dot(x,w)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def log_loss(x, y, w):\n",
    "    return (1/np.log(2))*np.log(1 + np.exp(-y*sigmoid(x,w)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(X[0, :], y[0], w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gradient_general()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradient_descent(x, y, w0, loss_func):\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
